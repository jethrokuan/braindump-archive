<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2018-10-04 Thu 21:36 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Machine Learning</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Jethro Kuan" />
<link rel="stylesheet" type="text/css" href="https://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
<link rel="stylesheet" type="text/css" href="https://www.pirilampo.org/styles/readtheorg/css/readtheorg.css"/>
<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script type="text/javascript" src="https://www.pirilampo.org/styles/lib/js/jquery.stickytableheaders.js"></script>
<script type="text/javascript" src="https://www.pirilampo.org/styles/readtheorg/js/readtheorg.js"></script>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2018 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Machine Learning</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org47ba749">1. The Learning Problem</a>
<ul>
<li><a href="#org9d20cae">1.1. What is Learning?</a>
<ul>
<li><a href="#org34c240a">1.1.1. Inductive Bias</a></li>
</ul>
</li>
<li><a href="#org70dc96c">1.2. Types of Learning</a>
<ul>
<li><a href="#org4b6cf0e">1.2.1. Active vs Passive Learning</a></li>
<li><a href="#org7cc1b9d">1.2.2. Online vs Batch Learning</a></li>
<li><a href="#org610bda4">1.2.3. Reinforcement Learning</a></li>
<li><a href="#orgd15fa7d">1.2.4. Supervised Learning</a>
<ul>
<li><a href="#org3ac2fe6">1.2.4.1. Measure of success</a></li>
<li><a href="#org775da52">1.2.4.2. Empirical Risk Minimisation (ERM)</a></li>
<li><a href="#org76fc303">1.2.4.3. Assumptions Made ⚠</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org4e06735">1.3. Is Learning Feasible?</a>
<ul>
<li><a href="#orgc3bc35d">1.3.1. Probabilistic View</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgbbaf8db">2. Training vs Testing</a>
<ul>
<li><a href="#orgb1ec93c">2.1. Generalisation Error</a></li>
<li><a href="#orgc1abd7f">2.2. Growth Function</a></li>
</ul>
</li>
<li><a href="#orgde3ff13">3. Concept Learning</a>
<ul>
<li><a href="#org65092e7">3.1. Hypothesis</a></li>
<li><a href="#org9349c17">3.2. Inductive Learning</a></li>
<li><a href="#orga2ea524">3.3. Concept Learning is Search</a></li>
<li><a href="#orgd42bbc9">3.4. Exploit Structure in Concept Learning</a></li>
<li><a href="#org834d34f">3.5. Find-S Algorithm</a>
<ul>
<li><a href="#org37095e4">3.5.1. Limitations</a></li>
</ul>
</li>
<li><a href="#org168335f">3.6. Version Space</a></li>
<li><a href="#org8ef46c6">3.7. List-Then-Eliminate Algorithm</a></li>
<li><a href="#org5afd5ad">3.8. Candidate-Elimination Algorithm</a></li>
</ul>
</li>
<li><a href="#orgf2ca9ee">4. Decision Tree Learning</a>
<ul>
<li><a href="#orga10461e">4.1. ID3 algorithm</a>
<ul>
<li><a href="#org01753fa">4.1.1. Which is the best attribute?</a></li>
<li><a href="#orgf3de7d7">4.1.2. Hypothesis Space Search</a></li>
<li><a href="#orge55f6fd">4.1.3. Inductive bias</a></li>
<li><a href="#org8116a7a">4.1.4. Why Prefer Shorter Hypotheses?</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orga76cd44">5. Density Estimation</a></li>
<li><a href="#org8e9c163">6. Unsupervised Learning</a>
<ul>
<li><a href="#orgf4a397e">6.1. K-means Clustering</a></li>
<li><a href="#orga30ab18">6.2. Gaussian Mixture Model</a></li>
<li><a href="#org9f33fe1">6.3. Expectation Maximization</a></li>
</ul>
</li>
<li><a href="#org8f2dbe4">7. Refile</a>
<ul>
<li><a href="#org3a4bc05">7.1. Data Compression</a></li>
</ul>
</li>
<li><a href="#org70fe1b7">8. Riken AIP Workshop</a>
<ul>
<li><a href="#org45b5a6c">8.1. Weakly Supervised Classification</a>
<ul>
<li><a href="#orgd2f8813">8.1.1. Motivation</a></li>
<li><a href="#org59545d0">8.1.2. Supervised Classification</a></li>
<li><a href="#orgd092f34">8.1.3. Unsupervised Classification</a></li>
<li><a href="#org63f28eb">8.1.4. Semi-supervised Classification</a></li>
<li><a href="#org69a7e0d">8.1.5. Positive Unlabelled Classification</a></li>
<li><a href="#org06d5e92">8.1.6. PNU Classification</a></li>
<li><a href="#org6b54e60">8.1.7. Pconf Classification</a></li>
</ul>
</li>
<li><a href="#orgcbeb8a0">8.2. Fast Computation of Uncertainty in Deep Learning</a>
<ul>
<li><a href="#orgcaec024">8.2.1. Uncertainty in Deep Learning</a></li>
<li><a href="#org03e70e5">8.2.2. Approximating Inference with Gradients</a></li>
</ul>
</li>
<li><a href="#org88d6628">8.3. Data-efficient Probabilistic Machine Learning</a>
<ul>
<li><a href="#org52a777a">8.3.1. Gaussian Process</a></li>
<li><a href="#org9a83db5">8.3.2. Task Setting</a></li>
<li><a href="#orge3a9351">8.3.3. Lipschitz Continuous Reward Functions</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org95a86c7">9. The Natural Language Decathlon: Multitask Learning as Question Answering: Richard Socher</a>
<ul>
<li><a href="#org7d8e0d1">9.1. Limits of Single-task Learning</a></li>
<li><a href="#orgc7ea353">9.2. Why has weight &amp; model sharing not happened so much in NLP?</a></li>
<li><a href="#org7879fc8">9.3. Motivation for Single Multitask model</a></li>
<li><a href="#org7cd0bb2">9.4. The 3 equivalent supertasks of NLP</a></li>
<li><a href="#org1f51fe5">9.5. Multitask learning as QA</a></li>
<li><a href="#orgca2742c">9.6. Designing a model for decaNLP</a></li>
<li><a href="#orgd9b826e">9.7. Learnings</a></li>
<li><a href="#org7708eee">9.8. Training Strategies</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org47ba749" class="outline-2">
<h2 id="org47ba749"><span class="section-number-2">1</span> The Learning Problem</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org9d20cae" class="outline-3">
<h3 id="org9d20cae"><span class="section-number-3">1.1</span> What is Learning?</h3>
<div class="outline-text-3" id="text-1-1">
<p>
An agent is said to be <i>learning</i> if it improves its performance P on
task T based on experience/observations/data E. T must be fixed, P
must be measurable, E must exist. See <a href="artificial_intelligence.html#org3546d1f">Learning Agents</a>.
</p>
</div>
<div id="outline-container-org34c240a" class="outline-4">
<h4 id="org34c240a"><span class="section-number-4">1.1.1</span> Inductive Bias</h4>
<div class="outline-text-4" id="text-1-1-1">
<p>
The incorporation of prior knowledge biases the learning mechanism.
This is also called <i>inductive bias</i>. The incorporation of prior
knowledge is inevitable for the success of learning algorithms (the
no-free-lunch theorem). The stronger the prior knowledge that one
starts the learning process with, the easier it is to learn from
further examples.
</p>
</div>
</div>
</div>
<div id="outline-container-org70dc96c" class="outline-3">
<h3 id="org70dc96c"><span class="section-number-3">1.2</span> Types of Learning</h3>
<div class="outline-text-3" id="text-1-2">
</div>
<div id="outline-container-org4b6cf0e" class="outline-4">
<h4 id="org4b6cf0e"><span class="section-number-4">1.2.1</span> Active vs Passive Learning</h4>
<div class="outline-text-4" id="text-1-2-1">
<p>
An active learner interacts with the environment at training time,
(e.g. by posing queries or performing experiments), while a passive
learner only observes the information provided by the environment.
</p>
</div>
</div>
<div id="outline-container-org7cc1b9d" class="outline-4">
<h4 id="org7cc1b9d"><span class="section-number-4">1.2.2</span> Online vs Batch Learning</h4>
<div class="outline-text-4" id="text-1-2-2">
<p>
In online learning, the hypothesis has to be updated each time a new
label is received.
</p>
</div>
</div>
<div id="outline-container-org610bda4" class="outline-4">
<h4 id="org610bda4"><span class="section-number-4">1.2.3</span> Reinforcement Learning</h4>
<div class="outline-text-4" id="text-1-2-3">
<p>
Each action in a state has an associated cost and a probability
distribution of the next state.
</p>

<p>
Goal is to learn a policy (mapping from state to action) that
minimizes the sum of expected current and future costs.
</p>
</div>
</div>
<div id="outline-container-orgd15fa7d" class="outline-4">
<h4 id="orgd15fa7d"><span class="section-number-4">1.2.4</span> Supervised Learning</h4>
<div class="outline-text-4" id="text-1-2-4">
</div>
<div id="outline-container-org3ac2fe6" class="outline-5">
<h5 id="org3ac2fe6"><span class="section-number-5">1.2.4.1</span> Measure of success</h5>
<div class="outline-text-5" id="text-1-2-4-1">
<p>
A loss function helps measure our success. Given a set \(H\) of
hypothesis of models, and a domain \(Z\), let \(l\) be a function from \(H
  \times Z\) to non-negative real numbers $l: \(H \times Z \rightarrow
  \mathbb{R}_{+}\).
</p>

<p>
The <i>risk function</i> is the expected loss of the hypothesis,
</p>

\begin{equation*}
  L_D(h) = E_{z \sim D}[l(h,z)]
\end{equation*}

<p>
We are interested in finding a hypothesis \(h\) that has a small risk,
or expected loss.
</p>
</div>
</div>
<div id="outline-container-org775da52" class="outline-5">
<h5 id="org775da52"><span class="section-number-5">1.2.4.2</span> Empirical Risk Minimisation (ERM)</h5>
<div class="outline-text-5" id="text-1-2-4-2">
<ul class="org-ul">
<li>The training set error is often called the <i>empirical error</i> or
<i>empirical risk</i>.</li>
<li>Given a hypothesis class \(H\), finding the hypothesis \(h \in H\) that
minimizes the empirical risk is a simple learning strategy.</li>
</ul>
</div>
</div>
<div id="outline-container-org76fc303" class="outline-5">
<h5 id="org76fc303"><span class="section-number-5">1.2.4.3</span> Assumptions Made ⚠</h5>
<div class="outline-text-5" id="text-1-2-4-3">
<ol class="org-ol">
<li>One common assumption is that the data in the data generation
process is independently and identically distributed (IID),
according to the distribution \(D\).</li>
</ol>

<p>
Q: Given a large enough training set, do you expect the long term test
error to be similar to the training error?
</p>

<ul class="org-ul">
<li>If IID, then yes</li>
<li>If not, there is likely dependencies, but under certain conditions,
yes.
<ul class="org-ul">
<li>If sampling mixes well, it will not take long for D' to look
like a steady set distribution.</li>
</ul></li>
<li>If dependencies are exploited, there is a possibility of attaining
lower training and test error.</li>
</ul>
</div>
</div>
</div>
</div>
<div id="outline-container-org4e06735" class="outline-3">
<h3 id="org4e06735"><span class="section-number-3">1.3</span> Is Learning Feasible?</h3>
<div class="outline-text-3" id="text-1-3">
<p>
The target function \(f\) that we want to learn is unknown. The
performance of a hypothesis on the training set \(D\) tells us nothing
about the performance on the data outside of \(D\).
</p>

<p>
As long as \(f\) is unknown, knowing \(D\) cannot exclude any patterns of
\(f\) outside of \(D\), and the predictions of \(g\) would be meaningless.
</p>
</div>
<div id="outline-container-orgc3bc35d" class="outline-4">
<h4 id="orgc3bc35d"><span class="section-number-4">1.3.1</span> Probabilistic View</h4>
<div class="outline-text-4" id="text-1-3-1">
<p>
If we accept a probabilistic answer, that is \(D\) tells us something
likely about \(f\) outside of \(D\), then learning is feasible, only with
a small price.
</p>

<p>
Learning a hypothesis \(g\) approximates the target function \(f\) well,
i.e. \(E_{out}(g) \approx 0\). However, probabilistic analysis via
Hoeffding's Inequality gives \(E_{out}(g) \approx E_{in}(g)\).
Therefore, we still need to ensure \(E_{in}(g) \approx 0\).
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-orgbbaf8db" class="outline-2">
<h2 id="orgbbaf8db"><span class="section-number-2">2</span> Training vs Testing</h2>
<div class="outline-text-2" id="text-2">
</div>
<div id="outline-container-orgb1ec93c" class="outline-3">
<h3 id="orgb1ec93c"><span class="section-number-3">2.1</span> Generalisation Error</h3>
<div class="outline-text-3" id="text-2-1">
<p>
We can define generalisation error as the discrepancy between \(E_in\)
and \(E_out\). The Hoeffding Inequality characterises the generalization
error with a probabilistic bound:
</p>

\begin{align}
P[|E_{in}(g) - E_{out}(g)| > \epsilon] \le 2Me^{-2\epsilon^2N}
\end{align}

<p>
Pick a tolerance level \(\delta\), and assert with probability
\(1-\delta\) that
</p>

\begin{align}
  E_{out}(g) \le E_{in}(g) + \sqrt{\frac{1}{2N}\ln \frac{2M}{\delta}}
\end{align}

<p>
Notice the error bound depends on \(M\), the size of the hypothesis
set \(H\). Most learning models have infinite \(H\), including the simple
perceptron. Hence, to study generalisation in such models, we need to
derive a counterpart that deals with infinite \(H\).
</p>

<p>
Notice that the \(M\) factor was obtained by taking the disjunction of
events. Let \(B_m\) be the bad event that \(|E_{in}(h_m) - E_{out}(h_m)|
> \epsilon\). Notice that these bad events are often strongly
overlapping, and the disjunction of these events form a much smaller
area.
</p>

<p>
The mathematical theory of generalisation hinges on this observation.
Upon accounting for the overlaps of different hypotheses, we will be
able to replace the number of hypotheses \(M\) with an effective finite
number, even while \(M\) is infinite.
</p>
</div>
</div>
<div id="outline-container-orgc1abd7f" class="outline-3">
<h3 id="orgc1abd7f"><span class="section-number-3">2.2</span> Growth Function</h3>
<div class="outline-text-3" id="text-2-2">
<p>
The <i>growth function</i> is the quantity that will formalize the
effective number of hypotheses.
</p>

<p>
Each \(h \in H\) generates a dichotomy which is \(h\) is \(-1\) or \(h\) i-
\(+1\). We then formally define dichotomies as follows:
</p>

\begin{align}
H(x_1, \dots, x_n) = \left\{ h(x_1), h(x_2), \dots, h(x_n) | h \in H \right\}
\end{align}
</div>
</div>
</div>

<div id="outline-container-orgde3ff13" class="outline-2">
<h2 id="orgde3ff13"><span class="section-number-2">3</span> Concept Learning</h2>
<div class="outline-text-2" id="text-3">
<p>
A concept is a boolean-valued function over a set of input instances
(each comprising input attributes). Concept learning is a form of
supervised learning. Infer an unknown boolean-valued function from
training-examples.
</p>
</div>
<div id="outline-container-org65092e7" class="outline-3">
<h3 id="org65092e7"><span class="section-number-3">3.1</span> Hypothesis</h3>
<div class="outline-text-3" id="text-3-1">
<p>
There is a trade-off between <i>expressive power</i> and smaller
<i>hypothesis space</i>. Large hypothesis spaces are bad, because search is
going to take a long time, and also requires more data. Humans exploit
structure in the hypothesis space to guide search and learn faster.
</p>

<p>
A hypothesis \(h\) is consistent with a set of training examples \(D\) iff
\(h(x) = c(x)\) for all \(<x,c(x)> \in D\).
</p>
</div>
</div>
<div id="outline-container-org9349c17" class="outline-3">
<h3 id="org9349c17"><span class="section-number-3">3.2</span> Inductive Learning</h3>
<div class="outline-text-3" id="text-3-2">
<p>
Any hypothesis found to approximate the target function well over a
sufficient large set of <b>training examples</b> will also approximate the
target function well over other <b>unobserved examples</b>.
</p>
</div>
</div>
<div id="outline-container-orga2ea524" class="outline-3">
<h3 id="orga2ea524"><span class="section-number-3">3.3</span> Concept Learning is Search</h3>
<div class="outline-text-3" id="text-3-3">
<p>
The goal is to search for a hypothesis \(h \in H\) that is consistent
with \(D\).
</p>
</div>
</div>
<div id="outline-container-orgd42bbc9" class="outline-3">
<h3 id="orgd42bbc9"><span class="section-number-3">3.4</span> Exploit Structure in Concept Learning</h3>
<div class="outline-text-3" id="text-3-4">
<p>
\(h_j\) is more general than or equal to \(h_k\) (denoted \(h_j \ge_{g}
h_k\)) iff any input instance \(x\) that satisfies \(h_j\) also satisfies
\(h_k\).
</p>

<p>
This is relation is a <b>partial order</b>.
</p>
</div>
</div>

<div id="outline-container-org834d34f" class="outline-3">
<h3 id="org834d34f"><span class="section-number-3">3.5</span> Find-S Algorithm</h3>
<div class="outline-text-3" id="text-3-5">
<p>
Intuition: Start with the most specific hypothesis \(h\). Whenever it
wrongly classifies a positive training example, we "minimally"
generalize it to satisfy its input instance.
</p>
</div>
<div id="outline-container-org37095e4" class="outline-4">
<h4 id="org37095e4"><span class="section-number-4">3.5.1</span> Limitations</h4>
<div class="outline-text-4" id="text-3-5-1">
<ol class="org-ol">
<li>Can't tell whether Find-S has learnt the target concept</li>
<li>Can't tell when training examples are <i>inconsistent</i></li>
<li>Picks a maximally specific \(h\)</li>
<li>Depending on \(H\), there may be several solutions</li>
</ol>
</div>
</div>
</div>
<div id="outline-container-org168335f" class="outline-3">
<h3 id="org168335f"><span class="section-number-3">3.6</span> Version Space</h3>
<div class="outline-text-3" id="text-3-6">
\begin{equation*}
  VS_{H,D} = {h \in H | h \text{ is consistent with }D}
\end{equation*}

<ul class="org-ul">
<li>If \(c \in H\), then D can reduce \(VS_{H,D}\) to \({c}\).</li>
<li>If D is insufficient, then \(VS_{H,D}\) represents the <i>uncertainty</i>
of what the target concept is</li>
<li>\(VS_{H,D}\) contains all consistent hypotheses, including maximally
specific hypotheses</li>
</ul>

<p>
The <b>general boundary</b> G of \(VS_{H,D}\) is the set of maximally general
members of \(H\) consistent with \(D\).
</p>

<p>
The <b>specific boundary</b> S of \(VS_{H,D}\) is the set of maximally general
members of \(H\) consistent with \(D\).
</p>

\begin{equation*}
  VS_{H,D} = {h \in H | \exists s \in S \exists g \in G g \ge_g h
    \ge_g s }
\end{equation*}
</div>
</div>

<div id="outline-container-org8ef46c6" class="outline-3">
<h3 id="org8ef46c6"><span class="section-number-3">3.7</span> List-Then-Eliminate Algorithm</h3>
<div class="outline-text-3" id="text-3-7">
<p>
Iterate through all hypotheses in \(H\), and eliminate any hypothesis
found inconsistent with any training example. This algorithm is often
prohibitively expensive.
</p>
</div>
</div>

<div id="outline-container-org5afd5ad" class="outline-3">
<h3 id="org5afd5ad"><span class="section-number-3">3.8</span> Candidate-Elimination Algorithm</h3>
<div class="outline-text-3" id="text-3-8">
<p>
Start with most general and specific hypotheses. Each training example
"minimally" generalizes S and specializes G to remove inconsistent
hypotheses from version space.
</p>
</div>
</div>
</div>
<div id="outline-container-orgf2ca9ee" class="outline-2">
<h2 id="orgf2ca9ee"><span class="section-number-2">4</span> Decision Tree Learning</h2>
<div class="outline-text-2" id="text-4">
<p>
<i>Decision Tree Learning</i> is a method of learning which approximates
discrete-valued functions that is robust to noisy data, and is capable
of learning disjunctive expressions
</p>

<p>
It is most appropriate when:
</p>
<ol class="org-ol">
<li>instances are represented as attribute pairs</li>
<li>the target function has discrete output values</li>
<li>Disjunctive descriptions may be required</li>
<li>The training data may contain errors</li>
<li>The training data may contain missing attribute values</li>
</ol>
</div>
<div id="outline-container-orga10461e" class="outline-3">
<h3 id="orga10461e"><span class="section-number-3">4.1</span> ID3 algorithm</h3>
<div class="outline-text-3" id="text-4-1">
<p>
ID3 learns decision trees by constructing them top down. Each instance
attribute is evaluated using a statistical test to determine how well
it alone classifies the examples. The best attribute is selected and
used as the test at the root node of the tree.
</p>
</div>
<div id="outline-container-org01753fa" class="outline-4">
<h4 id="org01753fa"><span class="section-number-4">4.1.1</span> Which is the best attribute?</h4>
<div class="outline-text-4" id="text-4-1-1">
<p>
A statistical property called <i>information gain</i> measures how well a
given attribute separates the training examples according to their
target classification.
</p>

<p>
Information gain is the expected reduction in entropy caused by
partitioning the examples according to this attribute:
</p>

\begin{align}
  Gain(S,A) = Entropy(S) - \sum_{v\in Values(A)}\frac{|S_v|}{|S|}Entropy(S_v)
\end{align}

<p>
For example:
</p>

\begin{align}
  Values(Wind) &= Weak, Strong \\
  S &= [9+, 5-] \\
  S_{Weak} &\leftarrow [6+, 2-] \\
  S_{Strong} &\leftarrow [3+, 3-] \\
  Gain(S, Wind) &= Entropy(S) - \frac{8}{14}Entropy(S_{Weak}) -
                  \frac{6}{14}Entropy(S_{Strong}) \\
               &=0.048
\end{align}
</div>
</div>
<div id="outline-container-orgf3de7d7" class="outline-4">
<h4 id="orgf3de7d7"><span class="section-number-4">4.1.2</span> Hypothesis Space Search</h4>
<div class="outline-text-4" id="text-4-1-2">
<p>
ID3 can be characterised as searching a space of hypotheses for one
that fits the training examples. The hypothesis space searched is the
set of possible decision trees. ID3 performs a simple-to-complex,
hill-climbing search. The evaluation measure that guides the search is
the information gain measure.
</p>

<p>
Because ID3's hypothesis space of all decision trees is a complete
space of finite discrete-valued functions, it avoids the risk that the
hypothesis space might not contain the target function.
</p>

<p>
ID3 maintains only a single hypothesis as it searches through the
space of decision trees. ID3 loses the capabilities that follow from
explicitly representing all consistent hypothesis.
</p>

<p>
ID3 in its pure form performs no backtracking in its search, and can
result in locally but not globally optimal target functions.
</p>

<p>
ID3 uses all training examples at each step to make statistically
based decisions, unlike other algorithms that make decisions incrementally.
</p>
</div>
</div>
<div id="outline-container-orge55f6fd" class="outline-4">
<h4 id="orge55f6fd"><span class="section-number-4">4.1.3</span> Inductive bias</h4>
<div class="outline-text-4" id="text-4-1-3">
<p>
The inductive bias of decision tree learning is that shorter trees are
preferred over larger trees (Occam's razor). Trees that place high
information gain attributes close to the root are preferred over those
that do not. ID3 can be viewed as a greedy heuristic search for the
shortest tree without conducting the entire breadth-first search
through the hypothesis space.
</p>

<p>
Notice that ID3 searches a complete hypothesis space incompletely, and
candidate-elimination searches an incomplete hypothesis space
completely. The inductive bias of ID3 follows from its search strategy
(<i>preference bias</i>), while that of candidate elimination follows from
the definition of its search space. (<i>restriction bias</i>).
</p>
</div>
</div>
<div id="outline-container-org8116a7a" class="outline-4">
<h4 id="org8116a7a"><span class="section-number-4">4.1.4</span> Why Prefer Shorter Hypotheses?</h4>
<div class="outline-text-4" id="text-4-1-4">
<ol class="org-ol">
<li>fewer shorter hypothesis than larger ones, means it's less likely
to over-generalise</li>
</ol>
</div>
</div>
</div>
</div>
<div id="outline-container-orga76cd44" class="outline-2">
<h2 id="orga76cd44"><span class="section-number-2">5</span> Density Estimation</h2>
<div class="outline-text-2" id="text-5">
<p>
<i>Density Estimation</i> refers to the problem of modeling the probability
distribution \(p(x)\) of a random variable \(x\), given a finite set \(x_1,
x_2, \dots, x_n\) of observations.
</p>

<p>
We first look at parametric distributions, which are governed by a
small number of adaptive parameters. In a frequentist treatment, we
choose specific values for the parameters optimizing some criterion,
such as the likelihood function. In a Bayesian treatment, we
introduce prior distributions and then use Bayes' theorem to compute
the corresponding posterior distribution given the observed data.
</p>

<p>
An important role is played by <i>conjugate priors</i>, which yield
posterior distributions of the same functional form.
</p>

<p>
The maximum likelihood setting for parameters can give severely
over-fitted results for small data sets. To develop a Bayesian
treatment to this problem, we consider a form of prior distribution
with similar form as the maximum likelihood function. this property is
called <i>conjugacy</i>. For a binomial distribution, we can choose the
beta distribution as the prior.
</p>
</div>
</div>
<div id="outline-container-org8e9c163" class="outline-2">
<h2 id="org8e9c163"><span class="section-number-2">6</span> Unsupervised Learning</h2>
<div class="outline-text-2" id="text-6">
<p>
In unsupervised learning, given a training set \(S = \left(x_1, \dots,
 x_m\right)\), without a labeled output, one must construct a "good"
model/description of the data.
</p>

<p>
Example use cases include:
</p>
<ul class="org-ul">
<li>clustering</li>
<li>dimension reduction to ind essential parts of the data and reduce
noise (e.g. PCA)</li>
<li>minimises description length of data</li>
</ul>
</div>
<div id="outline-container-orgf4a397e" class="outline-3">
<h3 id="orgf4a397e"><span class="section-number-3">6.1</span> K-means Clustering</h3>
<div class="outline-text-3" id="text-6-1">
<p>
Input: \(\{x^{(1), x^{(2)}, x^{(3)}, \dots, x^{(m)}}\}\).
</p>

<ol class="org-ol">
<li>Randomly initialize cluster centroids.</li>
<li>For all points, compute which cluster centroid is the closest.</li>
<li>For each cluster centroid, move centroids to the average points
belonging to the cluster.</li>
<li>Repeat until convergence.</li>
</ol>

<p>
K-means is guaranteed to converge. To show this, we define a
distortion function:
</p>

\begin{equation}
  J(c, \mu) = \sum_{i=1}^m || x^{(i)} - \mu_{c^{(i)}}||^2
\end{equation}

<p>
K means is coordinate ascent on J. Since \(J\) always decreases, the
algorithm converges.
</p>
</div>
</div>
<div id="outline-container-orga30ab18" class="outline-3">
<h3 id="orga30ab18"><span class="section-number-3">6.2</span> Gaussian Mixture Model</h3>
<div class="outline-text-3" id="text-6-2">
<p>
By Bayes' Theorem:
</p>

\begin{equation}
P(X^{(i)}, Z^{(i)}) = P(X^{(i)} | Z^{(i)})P(Z^{(i)})
\end{equation}

\begin{equation}
Z^{(i)} \sim \text{multinomial}(\phi)
\end{equation}

\begin{equation}
X^{(i)} | Z^{(j)} \sim \mathcal{N}(\mu_j, \Sigma_j)
\end{equation}
</div>
</div>

<div id="outline-container-org9f33fe1" class="outline-3">
<h3 id="org9f33fe1"><span class="section-number-3">6.3</span> Expectation Maximization</h3>
<div class="outline-text-3" id="text-6-3">
<p>
<a href="https://www.cs.utah.edu/~piyush/teaching/EM_algorithm.pdf">https://www.cs.utah.edu/~piyush/teaching/EM_algorithm.pdf</a>
</p>

<p>
The EM algorithm is an efficient iterative procedure to compute the
Maximum Likelihood (ML) estimate in the presence of missing or hidden
data.
</p>

<p>
Each iteration of the EM algorithm consists of two processes: The
E-step, and the M-step. In the expectation, or E-step, the missing da
ta are estimated given the observed data and current estimate of the
model par ameters. This is achieved using the conditional
expectation, explaining the choice of terminology.
</p>

<p>
In the M-step, the likelihood function is maximized under th e
assumption that the missing data are known. The estimate of the
missing data f rom the E-step are used in lieu of the actual missing
data.
</p>

<p>
Convergence is assured since the algorithm is guaranteed to
increase the likelihood at each iteration.
</p>


<div class="figure">
<p><img src="images/machine_learning/Expectation Maximization/screenshot_2018-04-03_10-56-25.png" alt="screenshot_2018-04-03_10-56-25.png" />
</p>
</div>

<p>
For mixture of Gaussians:
</p>

<p>
Repeat until convergence:
</p>
<ol class="org-ol">
<li>E-step
<ul class="org-ul">
<li>guess values of \(Z^{(i)}\)</li>
<li>Let \(w_j^{(i)} := P(Z^{(i)=j|X^{(i), \phi, \mu, \Sigma}})\)</li>
</ul></li>
<li>M-step
<ul class="org-ul">
<li>\(\phi_j := \frac{1}{m}\sum_{i=1}^m w_j^{(i)}\)</li>
<li>\(\mu_j := \frac{\sum_{i=1}^m w_j^{(i)}x^{(i)}}{\sum_{i=1}^m w_j^{(i)}}\)</li>
<li>&#x2026;</li>
</ul></li>
</ol>
</div>
</div>
</div>

<div id="outline-container-org8f2dbe4" class="outline-2">
<h2 id="org8f2dbe4"><span class="section-number-2">7</span> Refile</h2>
<div class="outline-text-2" id="text-7">
</div>
<div id="outline-container-org3a4bc05" class="outline-3">
<h3 id="org3a4bc05"><span class="section-number-3">7.1</span> Data Compression</h3>
<div class="outline-text-3" id="text-7-1">
<p>
In <i>lossy compression</i>, we seek to trade off code length with
reconstruction error.
</p>

<p>
In <i>vector quantization</i>, we seek a small set of vectors \({z_i}\) to
describe a large dataset of vectors \({x_i}\), such that we can
represent each \(x-i\) with its closest approximation in \({z_i}\) with
small error. (Clustering problem)
</p>

<p>
In <i>transform coding</i>, we transform the data, usually using a linear
tranformation. The data in the transformed domain is quantized,
usually discarding the small coefficients, corresponding to removing
some of the dimensions.
</p>
</div>
</div>
</div>
<div id="outline-container-org70fe1b7" class="outline-2">
<h2 id="org70fe1b7"><span class="section-number-2">8</span> Riken AIP Workshop</h2>
<div class="outline-text-2" id="text-8">
</div>
<div id="outline-container-org45b5a6c" class="outline-3">
<h3 id="org45b5a6c"><span class="section-number-3">8.1</span> Weakly Supervised Classification</h3>
<div class="outline-text-3" id="text-8-1">
</div>
<div id="outline-container-orgd2f8813" class="outline-4">
<h4 id="orgd2f8813"><span class="section-number-4">8.1.1</span> Motivation</h4>
<div class="outline-text-4" id="text-8-1-1">
<ul class="org-ul">
<li>Machine learning from big data is already successful</li>
<li>In some cases, massive labelled data is not available</li>
<li>Classification from limited information</li>
</ul>
</div>
</div>

<div id="outline-container-org59545d0" class="outline-4">
<h4 id="org59545d0"><span class="section-number-4">8.1.2</span> Supervised Classification</h4>
<div class="outline-text-4" id="text-8-1-2">
<p>
A large number of labeled samples yield better classification
performance.
Optimal convergence rate is \(O(n^{-\frac{1}{2}})\).
</p>
</div>
</div>

<div id="outline-container-orgd092f34" class="outline-4">
<h4 id="orgd092f34"><span class="section-number-4">8.1.3</span> Unsupervised Classification</h4>
<div class="outline-text-4" id="text-8-1-3">
<p>
Since collecting labelled samples is costly, we can learn a classifier
from unlabelled data. This is equivalent to clustering 
</p>
</div>
</div>

<div id="outline-container-org63f28eb" class="outline-4">
<h4 id="org63f28eb"><span class="section-number-4">8.1.4</span> Semi-supervised Classification</h4>
<div class="outline-text-4" id="text-8-1-4">
<ul class="org-ul">
<li>Use a large number of unlabelled samples and a small number of
labelled samples.</li>
<li>Find a decision boundary along cluster structure induced by
unlabelled samples.</li>
</ul>
</div>
</div>

<div id="outline-container-org69a7e0d" class="outline-4">
<h4 id="org69a7e0d"><span class="section-number-4">8.1.5</span> Positive Unlabelled Classification</h4>
<div class="outline-text-4" id="text-8-1-5">
<p>
Given positive and unlabelled samples:
</p>

\begin{equation}
{x_i^P}_{i=1}^{n_P} \sim P(x | y = + 1)
\end{equation}

\begin{equation}
  {x_i^U}_{i=1}^{n_U} \sim P(x)
\end{equation}

<p>
Risk of classifier can be decomposed into two terms:
</p>

<ol class="org-ol">
<li>Risk for positive data</li>
<li>Risk for negative data</li>
</ol>

<p>
Since we do not have negative data in the positive unlabelled data in
the PU setting, the risk cannot be directly estimated.
</p>

<p>
U-density is a mixture of positive and negative densities:
</p>

\begin{equation}
  R(f) = \pi E_{p(x|y=+1)} \left[ l(f(x)) \right] + (1-\pi) E_{p(x|y=-1)}\left[ l(-f(x)) \right]
\end{equation}

<p>
Through this we can find an unbiased risk estimator.
</p>

<p>
Estimating error bounds, we can show that PU learning can be better
than PN provided a large number of PU data.
</p>
</div>
</div>

<div id="outline-container-org06d5e92" class="outline-4">
<h4 id="org06d5e92"><span class="section-number-4">8.1.6</span> PNU Classification</h4>
<div class="outline-text-4" id="text-8-1-6">
<ul class="org-ul">
<li>Train PU, PN, and NU classification, and combine them.</li>
<li>Unlabelled data always helps without cluster assumptions</li>
<li>Use unlabelled data for loss evaluation (reducing the bias), not for
regularisation.</li>
</ul>
</div>
</div>

<div id="outline-container-org6b54e60" class="outline-4">
<h4 id="org6b54e60"><span class="section-number-4">8.1.7</span> Pconf Classification</h4>
<div class="outline-text-4" id="text-8-1-7">
<p>
Only positive data is available:
</p>
<ol class="org-ol">
<li>data from rival companies cannot be obtained</li>
<li>Only successful examples are available</li>
</ol>

<p>
If we have positive data with confidence, we can train a classifier.
</p>

<p>
Others: Similar-unlabelled etc.
</p>
</div>
</div>
</div>

<div id="outline-container-orgcbeb8a0" class="outline-3">
<h3 id="orgcbeb8a0"><span class="section-number-3">8.2</span> Fast Computation of Uncertainty in Deep Learning</h3>
<div class="outline-text-3" id="text-8-2">
<p>
Emtiyaz Khan
</p>

<p>
Uncertainty quantifies the confidence in the prediction of a model,
i.e., how much it does not know.
</p>
</div>

<div id="outline-container-orgcaec024" class="outline-4">
<h4 id="orgcaec024"><span class="section-number-4">8.2.1</span> Uncertainty in Deep Learning</h4>
<div class="outline-text-4" id="text-8-2-1">
<p>
<a href="https://emtiyaz.github.io/">https://emtiyaz.github.io/</a>
</p>

\begin{equation}
  p(D|\theta) = \prod_{i=1}^{N} p(y_i | f_\theta (x_i))
\end{equation}
<p>
Data given parameters,  output given NN(input)
</p>

<ol class="org-ol">
<li>Generate a prior distribution \(\theta \sim p(\theta)\)</li>
</ol>
</div>
</div>

<div id="outline-container-org03e70e5" class="outline-4">
<h4 id="org03e70e5"><span class="section-number-4">8.2.2</span> Approximating Inference with Gradients</h4>
<div class="outline-text-4" id="text-8-2-2">
\begin{equation}
  p(\theta | D) \approx q(\theta) = N(\theta | \mu, \sigma^2)
\end{equation}

<p>
Find the \(\mu\) and \(\sigma^2\) such that \(q\) is close to the posterior distribution.
</p>


\begin{equation}
  max L(\mu, \sigma^2) = E_q\left[ \log \frac{p(\theta)}{q(\theta)} \right] +
  \sum_{i=1}^N E_q \left[ \log p(D_i|\theta) \right]
\end{equation}

<p>
Using natural-gradients leads to faster and simpler algorithm than
gradients methods.
</p>
</div>
</div>
</div>

<div id="outline-container-org88d6628" class="outline-3">
<h3 id="org88d6628"><span class="section-number-3">8.3</span> Data-efficient Probabilistic Machine Learning</h3>
<div class="outline-text-3" id="text-8-3">
<p>
Bryan Low
</p>

<p>
Gaussian Process (GP) Models for Big Data.
</p>
</div>

<div id="outline-container-org52a777a" class="outline-4">
<h4 id="org52a777a"><span class="section-number-4">8.3.1</span> Gaussian Process</h4>
<div class="outline-text-4" id="text-8-3-1">
<ul class="org-ul">
<li>Is a rich class of Bayesian, non-parametric models</li>
<li>A GP is a collection of rvs any finite subset of which belongs to a
univariate</li>
</ul>
</div>
</div>

<div id="outline-container-org9a83db5" class="outline-4">
<h4 id="org9a83db5"><span class="section-number-4">8.3.2</span> Task Setting</h4>
<div class="outline-text-4" id="text-8-3-2">
<ul class="org-ul">
<li>Agent explores unknown environment modelled by GP</li>
<li>Every location has a reward</li>
</ul>
</div>
</div>

<div id="outline-container-orge3a9351" class="outline-4">
<h4 id="orge3a9351"><span class="section-number-4">8.3.3</span> Lipschitz Continuous Reward Functions</h4>
<div class="outline-text-4" id="text-8-3-3">
\begin{equation}
  R(z_t, s_t) \overset{\Delta}{=}  R_1(z_t) + R_2(z_t) + R_3(s_t)
\end{equation}

<ul class="org-ul">
<li>R<sub>1</sub> Lipschitz continuous (current measurement)</li>
<li>R<sub>2</sub> Lipschitz continuous after convolution with Gaussian kernel (current measurement)</li>
<li>R<sub>3</sub> Location History, independent of current measurement</li>
</ul>
</div>
</div>
</div>
</div>

<div id="outline-container-org95a86c7" class="outline-2">
<h2 id="org95a86c7"><span class="section-number-2">9</span> The Natural Language Decathlon: Multitask Learning as Question Answering: Richard Socher</h2>
<div class="outline-text-2" id="text-9">
<p>
<a href="https://einstein.ai/static/images/pages/research/decaNLP/decaNLP.pdf">pawper</a>
</p>

<ul class="org-ul">
<li>Joint work with Bryan McCann, Nitish Keskar and Caiming Xiong</li>
</ul>
</div>

<div id="outline-container-org7d8e0d1" class="outline-3">
<h3 id="org7d8e0d1"><span class="section-number-3">9.1</span> Limits of Single-task Learning</h3>
<div class="outline-text-3" id="text-9-1">
<ul class="org-ul">
<li>We can hill climb to local optima if \(|dataset| > 100 \times C\)</li>
<li>For more general model, we need continuous learning in a single model</li>
</ul>

<p>
For pre-training in NLP, we're still stuck at the word vector level.
This compared to vision, where most of the model can be pre-trained,
only retraining the final few layers.
</p>
</div>
</div>

<div id="outline-container-orgc7ea353" class="outline-3">
<h3 id="orgc7ea353"><span class="section-number-3">9.2</span> Why has weight &amp; model sharing not happened so much in NLP?</h3>
<div class="outline-text-3" id="text-9-2">
<ol class="org-ol">
<li>NLP requires many types of reasoning: logical, linguistic etc.</li>
<li>Requires short and long-term memory</li>
<li>NLP has been divided into intermediate and separate tasks to make
progress (Benchmark chasing in each community)</li>
<li>Can a single unsupervised task solve it all? No, language clearly
requires supervision in nature.</li>
</ol>
</div>
</div>

<div id="outline-container-org7879fc8" class="outline-3">
<h3 id="org7879fc8"><span class="section-number-3">9.3</span> Motivation for Single Multitask model</h3>
<div class="outline-text-3" id="text-9-3">
<ol class="org-ol">
<li>Step towards AGI</li>
<li>Important building block for:
<ol class="org-ol">
<li>Sharing weights</li>
<li>Transfer learning</li>
<li>Zero-shot learning</li>
<li>Domain adaptation</li>
</ol></li>
<li>Easier deployment in production</li>
<li>Lowering the bar for anybody to solve their NLP task</li>
</ol>

<p>
End2end model vs parsing as intermediate step (e.g. running POS tagger
first).
</p>
</div>
</div>

<div id="outline-container-org7cd0bb2" class="outline-3">
<h3 id="org7cd0bb2"><span class="section-number-3">9.4</span> The 3 equivalent supertasks of NLP</h3>
<div class="outline-text-3" id="text-9-4">
<p>
Any NLP task can be mapped to these 3 super tasks:
</p>

<ol class="org-ol">
<li>Language Modeling</li>
<li>Question Answering</li>
<li>Dialogue</li>
</ol>
</div>
</div>

<div id="outline-container-org1f51fe5" class="outline-3">
<h3 id="org1f51fe5"><span class="section-number-3">9.5</span> Multitask learning as QA</h3>
<div class="outline-text-3" id="text-9-5">
<ul class="org-ul">
<li>Question Answering</li>
<li>Machine Translation</li>
<li>Summarization</li>
<li>NLI</li>
<li>Sentiment Classification</li>
<li>Semantic Role Labeling</li>
<li>Relation Extraction</li>
</ul>

<p>
Meta supervised learning: {x, y} to {x, t, y}
</p>
</div>
</div>

<div id="outline-container-orgca2742c" class="outline-3">
<h3 id="orgca2742c"><span class="section-number-3">9.6</span> Designing a model for decaNLP</h3>
<div class="outline-text-3" id="text-9-6">
<ul class="org-ul">
<li>No task-specific modules or parameters because task ID assumed to be unavailable</li>
</ul>


<div class="figure">
<p><img src="images/The Natural Language Decathlon: Multitask Learning as Question Answering: Richard Socher/screenshot_2018-10-02_14-52-23.png" alt="screenshot_2018-10-02_14-52-23.png" />
</p>
</div>

<ol class="org-ol">
<li>Start with a context</li>
<li>Ask a question</li>
<li>Generate answer one at a time by
<ol class="org-ol">
<li>Pointing to context</li>
<li>Pointing to question</li>
<li>Choosing a word</li>
</ol></li>
</ol>
</div>
</div>

<div id="outline-container-orgd9b826e" class="outline-3">
<h3 id="orgd9b826e"><span class="section-number-3">9.7</span> Learnings</h3>
<div class="outline-text-3" id="text-9-7">
<ul class="org-ul">
<li>Transformer Layers yield benefits in single-task and multitask
setting</li>
<li>QA and SRL have strong connections</li>
<li>Pointing to the question is essential, despite the task being just
classification for some subtasks</li>
<li>Mulitasking helps a lot with zero-shot tasks</li>
</ul>

<p>
(Latest version of the paper coming out soon &#x2013; ICLR 2018)
</p>
</div>
</div>

<div id="outline-container-org7708eee" class="outline-3">
<h3 id="org7708eee"><span class="section-number-3">9.8</span> Training Strategies</h3>
<div class="outline-text-3" id="text-9-8">
<ul class="org-ul">
<li>Fully Joint</li>
<li>Curriculum learning doesn't work</li>
<li>Anti-curriculum training works instead
<ul class="org-ul">
<li>Start with a really hard task</li>
</ul></li>
</ul>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Jethro Kuan</p>
<p class="date">Created: 2018-10-04 Thu 21:36</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
